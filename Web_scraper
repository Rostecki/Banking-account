import requests
from bs4 import BeautifulSoup
import string
import os


def remove_punctuation(value):
    value = value.strip()
    for c in value:
        # If char is not punctuation, add it to the result.
        if c in string.punctuation: #  or c in ['’', '‘', '—']:
            value = value.replace(c, '')
    value = value.replace(' ', '_')
    return value


def get_request(url, number, type_of_art):
    for i in range(1, number + 1):
        # preparing directory and folder fo Pane_N
        tail_f = 'Page_' + str(i)
        path_f = 'C:\\Users\\Kamil\\PycharmProjects\\Web Scraper\\Web Scraper\\task\\'
        #directory = "".join(['C:\\Users\\Kamil\\PycharmProjects\\Web Scraper\\Web Scraper\\task\\', tail])
        os.mkdir(path_f + tail_f)
        os.chdir(path_f + tail_f)

        # getting requests
        r = requests.get(url + str(i), headers={'Accept-Language': 'en-US,en;q=0.5'})
        soup = BeautifulSoup(r.content, 'html.parser')
        articles = soup.find_all('article', {'class': 'u-full-height c-card c-card--flush'})
        # print(articles)
        for article in articles:
            news = article.find('span', class_='c-meta__type')
            # print(news.text)
            if news.text == type_of_art:
                find_link = article.find('a', {'data-track-action': 'view article'})
                tail = find_link.get('href')
                url_2 = 'https://www.nature.com' + tail
                r_sub = requests.get(url_2, headers={'Accept-Language': 'en-US,en;q=0.5'})
                soup_2 = BeautifulSoup(r_sub.content, 'html.parser')
                title = soup_2.find('h1', {'class': 'article-item__title'})
                # print(title.text)
                try:
                    body = soup_2.find('div', class_='article__body').text.strip()
                except AttributeError:
                    body = soup_2.find('div', class_='article-item__body').text.strip()

                body_byte = body.encode('utf-8')

                title = remove_punctuation(title.text)
                write_file(title, body_byte)

    os.chdir('C:\\Users\\Kamil\\PycharmProjects\\Web Scraper\\Web Scraper\\task\\')
    print('Saved all articles.')


def write_file(name, content):
    with open(name + '.txt', 'wb') as file:
        file.write(content)
    # print(f'zapisano plik: {name}\n')


def main():
    number_n = int(input())
    type_of_art = input()
    url = 'https://www.nature.com/nature/articles?searchType=journalSearch&sort=PubDate&page='
    get_request(url, number_n, type_of_art)


main()
